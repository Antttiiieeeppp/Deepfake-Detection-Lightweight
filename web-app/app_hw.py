# import streamlit as st
# import pandas as pd
# import numpy as np
# import time

# # Page configuration
# st.set_page_config(
#     page_title="Anttiep's Dashboard",
#     page_icon="ğŸ‚",
#     layout="wide",
#     initial_sidebar_state="expanded"
# )

# # Enable themes (if applicable)
# # Uncomment if using Altair or other visualization libraries with themes
# # import altair as alt
# # alt.themes.enable("dark")

# # Sidebar for navigation
# with st.sidebar:
#     st.title("Navigation")
#     page = st.radio("Choose a page:", ["Home", "Upload Image", "Upload Video", "About"])

# # Home Page
# if page == "Home":
#     st.title("ğŸ­ Team ANTTTIIIEEEPPP's Demo")
    
#     # Contributors Section
#     st.header("Contributors âœ¨", divider="grey")
    
#     # Contributor data
#     contributors = [
#         {
#             "name": "HyeongJun Kim",
#             "github": "https://github.com/hoooddy",
#             "avatar": "https://avatars.githubusercontent.com/u/35017649?v=4",
#         },
#         {
#             "name": "HyeonWoo Choi",
#             "github": "https://github.com/po2955",
#             "avatar": "https://avatars.githubusercontent.com/u/84663334?v=4",
#         },
#         {
#             "name": "JaeHee Lee",
#             "github": "https://github.com/JaeHeeLE",
#             "avatar": "https://avatars.githubusercontent.com/u/153152453?v=4",
#         },
#         {
#             "name": "Seunga Kim",
#             "github": "https://github.com/sinya3558",
#             "avatar": "https://avatars.githubusercontent.com/u/70243358?v=4",
#         },
#     ]
    
#     # Display contributors
#     cols = st.columns(len(contributors))
#     for col, contributor in zip(cols, contributors):
#         with col:
#             st.image(contributor["avatar"], width=100)
#             st.markdown(f"**[{contributor['name']}]({contributor['github']})**")
    
#     # Project Introduction
#     st.header("Project ì†Œê°œ :sunglasses:", divider=True)
#     multi = '''
#     :rainbow[ë”¥í˜ì´í¬ íƒì§€ ëª¨ë¸]ì€ ì´ë¯¸ ë†’ì€ ì„±ëŠ¥ì„ ê°–ì¶”ê³  ìˆìœ¼ë‚˜, ì—°ì‚° ìì›ì´ ì œí•œëœ í™˜ê²½ì—ì„œëŠ” í™œìš©ì´ ì œí•œì ì…ë‹ˆë‹¤.
#     ê·¸ë ‡ê¸°ì— ê²½ëŸ‰í™”ëœ ë”¥í˜ì´í¬ íƒì§€ ëª¨ë¸ë¡œ ì´ëŸ¬í•œ ê¸°ìˆ ì  ì¥ë²½ì„ ë‚®ì¶°,
#     ë‹¤ì–‘í•œ ê¸°ì—… ì‹œìŠ¤í…œ ë° ê¸°ì¡´ SNS í”Œë«í¼ì— ë”¥í˜ì´í¬ íƒì§€ ê¸°ëŠ¥ì„ ì†ì‰½ê²Œ í†µí•©í•˜ê³ ì í•©ë‹ˆë‹¤.
#     ë”¥í˜ì´í¬ í™•ì‚° ë°©ì§€ë¥¼ ìœ„í•œ ì‹¤ì‹œê°„ ëŒ€ì‘ì´ ê°€ëŠ¥í•œ ê²½ëŸ‰í™” AI ëª¨ë¸ ê°œë°œì„ ëª©í‘œë¡œ ë‘ê³  ìˆìŠµë‹ˆë‹¤.
#     '''
#     st.markdown(multi)
    
#     # Example Video Section
#     st.header("í”„ë¡œì íŠ¸ ë°°í¬ ì˜ˆì‹œ", divider=True)
#     VIDEO_URL = "https://www.youtube.com/watch?v=HhMPSuZgJsc"
#     st.video(VIDEO_URL)

# # Video Upload Page
# elif page == "Upload Video":
#     st.title("Detect Deepfakes in Videos")
#     uploaded_video = st.file_uploader("Upload a Video", type=["mp4"])   # ì¶”ê°€ í• ê²ƒ : avi, mov
    
#     if uploaded_video is not None:
#         st.video(uploaded_video)
#         st.markdown("**Analyzing video for deepfakes...**")
#         # Call your detection model here
#         # result = detect_video(uploaded_video)  # Example function
#         st.success("Deepfake detected!")  # Replace with your actual result

# # About Page
# elif page == "About":
#     st.title("About the Project")
#     st.markdown("""
#     This project aims to combat the misuse of deepfake technology by providing lightweight AI models 
#     capable of real-time detection in resource-limited environments. 
    
#     - **Team Members:** HyeongJun Kim, HyeonWoo Choi, JaeHee Lee, Seunga Kim
#     - **GitHub Repo:** [ğŸ’» Visit Our Repository](https://github.com/Antttiiieeeppp/Deepfake-Detection-Lightweight)
#     - **Technologies Used:** AI Models(EfficientNet-ViT, Cross Efficient-ViT), Python, Streamlit
#     """)

import streamlit as st
import cv2
import tempfile
import os
from PIL import Image
import numpy as np
import mediapipe as mp
import torch
import torch.nn.functional as F
import numpy as np

# í¬ë¡­ëœ ì´ë¯¸ì§€ë¥¼ ëª¨ë¸ì— ë„£ê¸° ìœ„í•œ ì „ì²˜ë¦¬ í•¨ìˆ˜
def preprocess_image(cropped_face):
    # OpenCVë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ í…ì„œë¡œ ë³€í™˜
    cropped_face = Image.fromarray(cv2.cvtColor(cropped_face, cv2.COLOR_BGR2RGB))
    cropped_face = cropped_face.resize((224, 224))  # ëª¨ë¸ì— ë§ëŠ” í¬ê¸°
    cropped_face = np.array(cropped_face).transpose((2, 0, 1))  # (H, W, C) -> (C, H, W)
    cropped_face = torch.tensor(cropped_face, dtype=torch.float32) / 255.0  # 0~1ë¡œ ì •ê·œí™”
    cropped_face = cropped_face.unsqueeze(0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
    return cropped_face

# ì˜ˆì¸¡ í•¨ìˆ˜
def predict(cropped_face):
    # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
    input_tensor = preprocess_image(cropped_face)
    
    # ëª¨ë¸ì— ì…ë ¥
    with torch.no_grad():
        output = model(input_tensor)  # ëª¨ë¸ì˜ ì¶œë ¥
        # ì¶œë ¥ì´ í™•ë¥ ì¼ ê²½ìš° (sigmoidë¥¼ í†µê³¼ì‹œì¼œì„œ 0~1ë¡œ ë§Œë“¤ê¸°)
        prob = torch.sigmoid(output)
        
        # í™•ë¥ ì„ 0.5 ê¸°ì¤€ìœ¼ë¡œ 1 ë˜ëŠ” 0ìœ¼ë¡œ ë³€í™˜
        prediction = 1 if prob > 0.5 else 0
    return prediction, prob.item()

# 2FPSë¡œ í”„ë ˆì„ ì¶”ì¶œ
def extract_frames(video_path, fps=2):
    cap = cv2.VideoCapture(video_path)
    original_fps = int(cap.get(cv2.CAP_PROP_FPS))
    frame_interval = original_fps // fps
    frames = []
    count = 0

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        if count % frame_interval == 0:
            frames.append(frame)
        count += 1

    cap.release()
    return frames
# ì–¼êµ´ ê°ì§€ ë° í¬ë¡­
def detect_and_crop_faces(frames):
    cropped_faces = []
    mp_face_detection = mp.solutions.face_detection
    face_detection = mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.7)  # min_detection_confidence ì¡°ì •

    for frame in frames:
        # ì–¼êµ´ ê°ì§€
        results = face_detection.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        if results.detections:
            for detection in results.detections:
                bboxC = detection.location_data.relative_bounding_box
                h, w, _ = frame.shape
                x, y, w_box, h_box = int(bboxC.xmin * w), int(bboxC.ymin * h), int(bboxC.width * w), int(bboxC.height * h)
                
                # ì–¼êµ´ í¬ë¡­
                cropped_face = frame[y:y + h_box, x:x + w_box]
                
                # 224x224ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
                resized_face = cv2.resize(cropped_face, (224, 224))
                cropped_faces.append(resized_face)
        else:
            cropped_faces.append(None)
    
    return cropped_faces


# Page configuration
st.set_page_config(
    page_title="Anttiep's Dashboard",
    page_icon="ğŸ‚",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Sidebar for navigation
with st.sidebar:
    st.title("Navigation")
    page = st.radio("Choose a page:", ["Home", "Upload Image", "Upload Video", "About"])

# Home Page
if page == "Home":
    st.title("ğŸ­ Team ANTTTIIIEEEPPP's Demo")
    
    # Contributors Section
    st.header("Contributors âœ¨", divider="grey")
    
    contributors = [
        {
            "name": "HyeongJun Kim",
            "github": "https://github.com/hoooddy",
            "avatar": "https://avatars.githubusercontent.com/u/35017649?v=4",
        },
        {
            "name": "HyeonWoo Choi",
            "github": "https://github.com/po2955",
            "avatar": "https://avatars.githubusercontent.com/u/84663334?v=4",
        },
        {
            "name": "JaeHee Lee",
            "github": "https://github.com/JaeHeeLE",
            "avatar": "https://avatars.githubusercontent.com/u/153152453?v=4",
        },
        {
            "name": "Seunga Kim",
            "github": "https://github.com/sinya3558",
            "avatar": "https://avatars.githubusercontent.com/u/70243358?v=4",
        },
    ]
    
    cols = st.columns(len(contributors))
    for col, contributor in zip(cols, contributors):
        with col:
            st.image(contributor["avatar"], width=100)
            st.markdown(f"**[{contributor['name']}]({contributor['github']})**")
    
    st.header("Project ì†Œê°œ :sunglasses:", divider=True)
    multi = '''
    :rainbow[ë”¥í˜ì´í¬ íƒì§€ ëª¨ë¸]ì€ ì´ë¯¸ ë†’ì€ ì„±ëŠ¥ì„ ê°–ì¶”ê³  ìˆìœ¼ë‚˜, ì—°ì‚° ìì›ì´ ì œí•œëœ í™˜ê²½ì—ì„œëŠ” í™œìš©ì´ ì œí•œì ì…ë‹ˆë‹¤.
    ê·¸ë ‡ê¸°ì— ê²½ëŸ‰í™”ëœ ë”¥í˜ì´í¬ íƒì§€ ëª¨ë¸ë¡œ ì´ëŸ¬í•œ ê¸°ìˆ ì  ì¥ë²½ì„ ë‚®ì¶°,
    ë‹¤ì–‘í•œ ê¸°ì—… ì‹œìŠ¤í…œ ë° ê¸°ì¡´ SNS í”Œë«í¼ì— ë”¥í˜ì´í¬ íƒì§€ ê¸°ëŠ¥ì„ ì†ì‰½ê²Œ í†µí•©í•˜ê³ ì í•©ë‹ˆë‹¤.
    ë”¥í˜ì´í¬ í™•ì‚° ë°©ì§€ë¥¼ ìœ„í•œ ì‹¤ì‹œê°„ ëŒ€ì‘ì´ ê°€ëŠ¥í•œ ê²½ëŸ‰í™” AI ëª¨ë¸ ê°œë°œì„ ëª©í‘œë¡œ ë‘ê³  ìˆìŠµë‹ˆë‹¤.
    '''
    st.markdown(multi)
    
    st.header("í”„ë¡œì íŠ¸ ë°°í¬ ì˜ˆì‹œ", divider=True)
    VIDEO_URL = "https://www.youtube.com/watch?v=HhMPSuZgJsc"
    st.video(VIDEO_URL)

# Video Upload Page
elif page == "Upload Video":
    st.title("Detect Deepfakes in Videos")
    uploaded_video = st.file_uploader("Upload a Video", type=["mp4", "avi", "mov"])   # ì¶”ê°€ í• ê²ƒ : avi, mov
    if uploaded_video is not None:
        st.video(uploaded_video)
        st.markdown("**Analyzing video for deepfakes...**")
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as temp_video:
            temp_video.write(uploaded_video.read())
            video_path = temp_video.name
        
        # 2FPSë¡œ í”„ë ˆì„ ì¶”ì¶œ
        frames = extract_frames(video_path, fps=2)
        total_frames = len(frames)
        st.write(f"Extracted {total_frames} frames from the video.")
        
        # ì–¼êµ´ ê°ì§€ ë° í¬ë¡­
        cropped_faces = detect_and_crop_faces(frames)
        total_cropped_faces = len(cropped_faces)
        st.write(f"Detected and cropped {total_cropped_faces} faces.")
        # st.write(cropped_faces)
        # í¬ë¡­ëœ ì–¼êµ´ ì¶œë ¥
        if cropped_faces:
            st.write("Cropped Faces:")
            for i, face in enumerate(cropped_faces):
                face_image = Image.fromarray(cv2.cvtColor(face, cv2.COLOR_BGR2RGB))
                st.image(face_image, caption=f"Cropped Face {i+1}", width=150)  # widthë¥¼ 150ìœ¼ë¡œ ì„¤ì •
        else:
            st.write("No faces detected in the video.")
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        os.remove(video_path)
        # í¬ë¡­ëœ ì´ë¯¸ì§€ ë”•ì…”ë„ˆë¦¬ë¡œ ë§Œë“¤ê¸°
        cropped_faces_dict = {index: value for index, value in enumerate(cropped_faces)}
        #ë§Œë“  ë”•ì…”í„°ë¦¬ ì¶œë ¥
        st.write(cropped_faces_dict)
        
# About Page
elif page == "About":
    st.title("About the Project")
    st.markdown("""
    This project aims to combat the misuse of deepfake technology by providing lightweight AI models 
    capable of real-time detection in resource-limited environments. 
    
    - **Team Members:** HyeongJun Kim, HyeonWoo Choi, JaeHee Lee, Seunga Kim
    - **GitHub Repo:** [ğŸ’» Visit Our Repository](https://github.com/Antttiiieeeppp/Deepfake-Detection-Lightweight)
    - **Technologies Used:** AI Models(EfficientNet-ViT, Cross Efficient-ViT), Python, Streamlit
    """)

# Helper functions for video processing
def extract_frames(video_path, fps=2):
    cap = cv2.VideoCapture(video_path)
    frames = []
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        frames.append(frame)
    cap.release()
    
    # FPSì— ë§ì¶° í”„ë ˆì„ì„ ì¶”ì¶œ
    total_frames = len(frames)
    interval = int(total_frames / (fps * (total_frames / 30)))  # FPSì— ë§ëŠ” ê°„ê²© ê³„ì‚°
    selected_frames = frames[::interval]  # 2FPSë¡œ í”„ë ˆì„ ì„ íƒ
    return selected_frames

def detect_and_crop_faces(frames):
    cropped_faces = []
    mp_face_detection = mp.solutions.face_detection
    face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)
    
    for frame in frames:
        # ì–¼êµ´ ê°ì§€
        results = face_detection.process(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        if results.detections:
            for detection in results.detections:
                bboxC = detection.location_data.relative_bounding_box
                h, w, _ = frame.shape
                x, y, w_box, h_box = int(bboxC.xmin * w), int(bboxC.ymin * h), int(bboxC.width * w), int(bboxC.height * h)
                
                # ì–¼êµ´ í¬ë¡­
                cropped_face = frame[y:y + h_box, x:x + w_box]
                
                # 224x224ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
                resized_face = cv2.resize(cropped_face, (224, 224))
                cropped_faces.append(resized_face)
    return cropped_faces